（项目介绍请查看About_this_project.md）

(一)技术栈学习与落地经验  
1.先聊一聊最开始踩坑PHP的版本吧  
  开始阶段考分析项目需求时感觉难度并不大，于是直接二话不说采用了比较熟悉的Windows Server2022+小皮面板+PHP+Redis+Apache来实现  
  真正开始测试后发现API请求接口在高频率并发的情况下CPU直接被打到100%的使用率，当时还并没有引进Redis来控制性能，后续在Ai的建议下引入了Redis来处理下发Release，但是实际测试情况下效果也并不理想，因为高频率的请求下导致服务端QPS极高，所下发的Release
  请求很难做到真正的同时进行，后续考虑到网络问题将下发方式改为下发执行时间（执行时间基于最后进入所限制阈值内客户端时间+用户在中控端设置的延时时间来下发一个时间戳），测试后感觉很beautiful，高频率跑了一下测试发现 坏了 怎么阈值控制又出问题了
  高频率的请求中有效请求极少，更多的请求是判断当前是否能Release，虽然已经做了轮询延时回复处理但是介于大数量客户端的基数下导致QPS仍居高不下导致Round正常已经为新轮次但旧的Round内扔卡着部分客户端请求 导致旧的客户端永远收不到Release，新的客户端永远被一个无法执行的Round轮次卡在那儿进不去阈值 这时考虑到实际测试结果决定放弃PHP采用MQTT集群控制来处理请求  
  
  一句话总结就是：“高并发下QPS被海量无意义计算淹没，即使有Redis缓存存在依旧会被打穿 果断采用新的Ubuntu 24.04.4 LTS + 宝塔面板”
  —————————————————————————————————————————————————————————————  
  （二）第二版核心技术  
  1.Python网络服务  
    最开始采用HTTPServer单线程来处理客户端所发送的请求，测试后因为客户端基数问题导致效果不理想，处理速度极慢，考虑到客户端基数问题和Release长轮询（wait_ms=2000）改为ThreadingHTTPServer来解决单线程堵塞问题,这样既可以实现多线程处理能力也能有效解决长轮询导致的拥堵问题从而解决Ready/hb/done等段请求在高并发下仍然能下发响应    
      
  2.RLock + Condition 控制长轮询唤醒机制  
    首先讲讲采用Rlock锁的作用吧 在我设计的系统架构里HTTP线程、MQTT回调线程以及主线程都可以访问或修改这些集合（online、ready、done、state、round_id、snapshot）不采用Lock锁的原因是害怕某个线程拿到锁后直接导致锁死采用Rlock可重入锁当某个线程拿到锁后可以在内部再次拿锁可以有效保护state与集合的并发读写避免导致多线程造成的线程竞争
    condition的作用主要是用来避免客户端高频率的轮询导致服务器长时间计算一些没必要的请求导致服务端QPS一直居高不下造成的网络负担，当某一台机器收到Release后会立刻唤醒所有wait等待状态的线程有效解决每台机器去高频发送一个没有意义的请求，这样当可以有效的将所有客户机的无意义请求优化成可通行后服务端主动广播一次  
    
  3.dataclass + snapshot 冻结结构  
先聊聊为什么要采用冻结结构 因为客户在中控端上传的config参数有可能是在WAITING阶段更新的但是我又要保证客户体验时EXECUTING阶段的稳定性不采用冻结机制就很容易造成一部分客户机拿到的是旧的config参数一部分后进入阈值内的客户机拿到的是新的config参数导致本轮次失去想要的效果 这时我引入一个snapshot机制在整套系统进入EXECUTING阶段时本轮次所调用的参数全部复制一份并锁死，这样就可以避免造成客户机拿到乱序的参数问题
    再聊聊使用dataclass的意义 这个就很简单明了了 “保证代码的整洁和后续维护”

  4.MQTT 协议应用  
   [1]Topic隔离意义  
   因为客户要求的应用端需要分为主从两个端 两端过程中所做的事情和需要的参数有区别 所以做了一个隔离来减少下发参数时还需要做大量的判断和过滤  
   
   [2]ready / hb / done / release 语义拆分
   ready参数主要作用为：“我准备好了，进入等待集合”
   hb参数主要作用为：“我现在还活着”
   done参数主要作用为：“我执行完了（他还需要round轮次参数作为校验）”
   release参数主要作用为：“由服务端整体调度下发执行许可（targets + buy_at）”   不采用下发立即执行而增加一个buy_at参数是考虑到高并发下可能的网络波动所造成的影响从而选择下发一个执行时间  
   
   [3]LWT机制+心跳验证用于断连自动离线
   这里主要是为了验证当前客户端是否还在线，总不能客户端已经掉线了还在傻等吧  
   但是因为Lua端并没有所需的库从而并未采用MQTT客户端直连，退而求其次采用了HTTP网关模式用心跳来校验机器是否在线，当机器掉线后自动出发leave从集合中剥离  
   
   [4]选择QoS=1  
   这个是通过技术档案来分析的具体适合哪种模式 如果采用QoS=0 在高并发下丢一条 done，那这轮很大概率会卡住，采用QoS=2又会造成成本过重问题所以采用了折中的QoS=1与round校验去重双重保障  
   —————————————————————————————————————————————————————————————  
   （三）状态机设计能力提升  
   1.因为参数在中控端由用户手动设置，但是个别参数的权重又很高需要根据情况实时调整，WAITING阶段当调整了参数后因为还没有放行所以价格可以修改  
     EXECUTING阶段是已经进入了执行阶段 当前设置的关键参数都需要使用了这时冻结结构就体现了他的价值  
     reset_round轮转清理 进入此阶段证明本轮次已经执行完毕 需要恢复到原始数据状态 这时他负责的三件事“清空 ready/done”/“round_id 更新”/“state 回到WAITING”同时并唤醒上一轮并没有进入阈值内但是已经进入Release请求阶段的客户机让他们别一直在那里傻等告诉他们“你可以干活了，别睡了”  
     超时与死亡阈值回滚 执行阶段如果迟迟未下发同行的信号时或者掉线客户端超出了用户所设定的阈值本轮次无法达到预期的要求时就会强制reset本轮避免导致系统永久性的卡住  
	 
 2.阈值动态收缩  
     举个简单的例子比如有100台从客户机 20台主客户机时用户设定的阈值为70/15 当主/从客户机因为已经完成任务退出时在当前在线机器数还高于阈值时并不会有太大影响 但是如果当前在线机器已经小于阈值的时候例如60/10的时候如果阈值不做动态调整就会导致一直在等根本不可能来的“他/她/它”这时候动态控制阈值的作用就体现出来了 在线机器≥阈值机器时按兵不动 在线机器＜阈值机器时出兵  
     —————————————————————————————————————————————————————————————  
     （四）核心Release设计 WAITING → EXECUTING
     [1]Release设计目的
     1.解决客户端高频无效轮询降低服务器计算降低QPS  
     2.解决因网络问题所造成的放行时间不一致  
	 
[2]Release核心定义  
     可以将Release理解为一个“冻结后的许可包”其中包含了四个关键信息"round(轮次编号)"/“targets{本轮次允许执行的Client_id（设备唯一标识）列表）}”/“buy_at（统一执行时间戳 绝对时间）”/“server_time（服务器发包时间，用于调试时客户端对时）”  
     一句话理解就是：“在这轮，这些人，在这个时间点执行”  
	 
[3]Release产生时机
     1.服务端调度器需求条件：在WAITING阶段持续手机online在线设备/Ready准备好的设备/Done执行完的设备（进入EXECUTING阶段才算）当三个条件均满足时才会Release	 
     2.关键条件（对应Python代码中maybe_release）：中控端必须上传过config参数 服务端中上传配置时间戳参数必须大于0、总在线数必须大于阈值需求的90%、将有效需求参数“eff_small = min(need_small, online_small)（阈值从客户端数量/在线从客户端数量）”、“eff_boss = min(need_boss , online_boss )（阈值主客户端数量/在线主客户端数量）”、Ready数量必须要够“ready >= eff_need（WAITING数量≥阈值需求）”满足条件后才会进入EXECUTING	
	 3.这一步的意义是做到Release只发一次，而且只发给“对的人”	
	 
[4]为什么要targets冻结	
	 一句话说明就是“为了系统稳定打下根基”	
	 如果不进行冻结会发生 “某个客户端先进来了说我准备好了”/“服务端没有一个合理的标准感觉差不多了就放行”/“放行过程中又有客户端进来说我准备好了”	
	 那么这轮到底谁才是参与者？有客户端收到Release了、有客户端没收到、有客户端收到了但是不该执行	
	 这时候引入一个冻结targets就能起到“固定本轮参与客户端”、“EXECUTNG阶段不再接受新的Ready进入集合”、“本轮只等待这些进入客户端的done 尤其是主客户端的done”	

[5]buy_at的作用	
	显而易见可以解决“客户端拿到 Release 的时间不一致”、“某些机子快，某些机子慢”、“高并发时差个 100-500ms 就足够让效果变成垃圾”	
	增加后客户端收到的是一个未来时间的执行许可网络抖动只影响提前多少收到	

[6]HTTP长轮询网关版Release降压原理	
	目前客户Lua端是HTTP长轮询模式，当客户端发送一个请求时服务器不会立刻算一堆逻辑而是等待条件成立后才会回应这些线程返回	
	这意味着客户端不需要高频率大批量的请求服务端问他“我能执行了吗？” 当Release出现后一次性的广播返回所有等待线程 极大的降低CPU的使用率	

[7]Release的生命周期总结	
	总结说明一个Release的流程周期为	
	1.客户端发 ready/hb，进入 online & ready（WAITING 期）
	2.服务端判定达到 online 阈值 + ready 阈值
	3.冻结 targets + 冻结 cfg/biz → snapshot
	4.计算 buy_at（base_delay + boss_extra）
	5.发布 Release（MQTT topic 或 HTTP release 返回）
	6.EXECUTING 阶段只统计 targets 的 done
	7.done 达标 / 超时 / 掉线超过阈值 → reset_round → 下一轮	
	—————————————————————————————————————————————————————————————	




	 
	 
	 
     
   
   
